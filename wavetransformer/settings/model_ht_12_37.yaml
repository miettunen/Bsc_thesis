## =================================
# Settings for the model.
#
# author: An Tran
# affiliation: Tampere University
# =================================
model_name: 'wave_transformer_10'
use_pre_trained_model: Yes
# -----------------------------------
encoder:
  in_channels_encoder:  64
  out_waveblock_encoder: [16,32,64,128] 
  kernel_size_encoder: 3 
  dilation_rates_encoder: [2,2,2,2]
  inner_kernel_size_encoder: 5
  inner_padding_encoder: 2
  last_dim_encoder: 128 
  pw_kernel_encoder: 5
  pw_padding_encoder: 2
  merge_mode_encoder: 'conv'
 # -----------------------------------
decoder:
  num_layers_decoder: 3
  num_heads_decoder: 4
  n_features_decoder: 128
  n_hidden_decoder: 128
  nb_classes: # Empty, to be filled automatically.
  dropout_decoder: .25
  beam_size: 0 
# EOF
